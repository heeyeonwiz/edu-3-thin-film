{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. 반도체 박막 모델 업그레이드  \n",
    "모델을 수정하여 손실값을 더 줄여 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1) 데이터 로드 : 전 단계에서 준비한 트레이닝용 데이터를 로드하여 모델 트레이닝에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # 경고 메시지 안보이게 설정\n",
    "\n",
    "import gc\n",
    "gc.collect() # garbage collector : 메모리 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "전역 변수 중 일부(디렉토리 이름과 파일 이름 등)는 대문자로  \n",
    "나머지 변수는 소문자로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로는 단순히 문자열 연결보다는 os.path.join()을 사용하는 것이 좋음 \n",
    "DATA_DIR = 'data'\n",
    "TRAIN_DATA_FILE = 'train-splited.csv'\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_DIR, TRAIN_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2) 성능을 향상시키디 위하여 네트워크 모델을 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (가) 사용자 정의 활성함수(Activation Function) 추가 : gelu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):  return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_custom_objects().update({'gelu': Activation(gelu)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (나) 네트워크 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 Sequential 모델을 정의합니다\n",
    "model = Sequential([\n",
    "  Dense(units=1024, activation='gelu', input_dim=226),\n",
    "  Dense(units=900, activation='gelu'),\n",
    "  Dropout(0.02),\n",
    "  Dense(units=1024, activation='gelu'),\n",
    "  Dense(units=512, activation='gelu'),\n",
    "  Dense(units=512, activation='gelu'),\n",
    "  Dense(units=4, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'model'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SUMMARY_FILE = \"thin_film_base_model.png\"\n",
    "MODEL_SUMMARY_PATH = os.path.join(MODEL_DIR, MODEL_SUMMARY_FILE)\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file = MODEL_SUMMARY_PATH, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (다) 체크포인트를 저장하기 콜백 만들기 : 에포크마타 모델 파일을 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_DIR = 'model'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "CHK_POINT_DIR = os.path.join(MODEL_DIR, 'upgrade_chk_point')\n",
    "Path(CHK_POINT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "# os.makedirs(CHK_POINT_DIR, exist_ok=True)\n",
    "\n",
    "CHK_POINT_FILE = '{epoch:002d}.h5'\n",
    "CHK_POINT_PATH =  os.path.join(CHK_POINT_DIR, CHK_POINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHK_POINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    CHK_POINT_PATH,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    mode='min',\n",
    "    save_weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (라) 텐서보드용 로그 저장 콜백 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_DIR = 'model'\n",
    "# from pathlib import Path\n",
    "\n",
    "TB_DIR = os.path.join(MODEL_DIR, 'tensorboard')\n",
    "Path(TB_DIR).mkdir(parents=True, exist_ok=True)\n",
    "# os.makedirs(CHK_POINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=TB_DIR,\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### (마) 러닝레이트 조정 콜백 만들기  \n",
    "손실 값이 잘 줄지 않을 때 러닝레이트를 더 작게 줄인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    # epsilon=1e-04,\n",
    "    min_delta=1e-04,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 콜백을 콜맥 리스트에 저장\n",
    "callbacks = [checkpoint, tensorboard, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size 2000일 때, NUC에서 epoch 당 약 135초\n",
    "# 5 epoch : mae = 15.1 (12분)\n",
    "# 10 epoch : mae = 6.8 (24분)\n",
    "# 15 epoch : mae = 4.5 (36분)\n",
    "# 20 epoch : mae = 3.5 (48분)\n",
    "\n",
    "\n",
    "# batch_size 1000일 때, NUC에서 epoch 당 약 151초\n",
    "# 5 epoch : mae = 7.5 (13분)\n",
    "\n",
    "# batch_size 500일 때, NUC에서 epoch 당 약 183초\n",
    "# 5 epoch : mae = 4.8 (15분)\n",
    "\n",
    "# batch_size 250일 때, NUC에서 epoch 당 약 240초\n",
    "# 5 epoch : mae = 4.45 (20분)\n",
    "\n",
    "# batch_size 200일 때, NUC에서 epoch 당 약 260초\n",
    "# 4 epoch : mae = 5.3 ()\n",
    "# 5 epoch : mae = 9.7 (1314 초)\n",
    "\n",
    "epoch_num = 5\n",
    "batch_size = 250 # 200 # 250 # 500 # 1000 # 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#독립변수와 종속변수를 분리합니다.\n",
    "train_X = train_df.iloc[:, 5:]\n",
    "train_Y = train_df.iloc[:, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 학습합니다.\n",
    "start = time.time() # start time\n",
    "\n",
    "history = model.fit(train_X, train_Y, epochs=epoch_num, batch_size=batch_size, validation_split=0.05, callbacks=callbacks)\n",
    "\n",
    "print(\"time : \", time.time() - start, \" sec\") # sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 측정값의 시각화.  \n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,loss,label='Training Loss')\n",
    "plt.plot(epochs,val_loss,label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
